---
title: "OpenCV 기초"
excerpt: ""

categories:
  - OpenCV
tags:
  - OpenCV
  - C++
---
# OpenCV 기초와 응용
### OpenCV 소개, 설치, 프로그래밍
- OpenCV 소개
  - 말그대로 컴퓨터 비전의 오픈 소스 프로그램
  - 내부로는 C로 작성되어 있지만 Python, Java에서도 실행 가능(내부를 C로 만들었기 때문에 빠르게 잘 동작함)
  - 거의 대부분의 OS에서 원활하게 작동함
  - CPU, GPU 등의 HW도 지원함
  - 영상처리가 주 목적이지만 머신러닝과 관련된 라이브러리도 활성화되는 중
  - BSD 라이선스(free and open 소스)
  - OpenCV는 상용화되어 사용할 때, copyright를 notice 해야함
  - 거의 대부분의 기업에서 모두 사용함
  - 셀 수 없는 스타트업에서 사용함
  - OpenCV의 Main modules에는 매우 많은 기능등이 있음
  
  - 1.x: C로 작성
  - 2.x: C++로 작성
  - 3.x: 라이브러리 파일이 하나로 합쳐짐
  - 4.x: 딥러닝 패키지 추가
  
- OpenCV의 설치
  - OpenCV가 작동하기 위해서 설치되어야 하는 것
    - 소스형태 파일
      - 헤더 소스 파일
      - 사전에 학습된 사물인식 설정 파일
  
    - 이진형태 파일
      - 라이브러리 (실행시)
      - 라이브러리 (컴파일 및 링크시)
      - 동영상 디코더 라이브러리
  
  - 개발 환경에서 설정해주는 사항
    - include 파일들의 경로(include/opencv/opencv2/opencv.hpp)
    - library 이전 파일들의 경로 및 파일명(경로: build/x64/vc15, 파일명: oepncv_world341.lib 또는 opencv_world341d.lib)
    * .lib 파일은 2가지 경우가 있음(숫자로 끝나면 릴리즈 모드, d로 끝나면 디버그 모드)
  
  - OpenCV 설치하는 두가지 방법
    - Win: 배포를 위해 이진화일 형태로 사전에 준비된 실행파일을 실행만 하기
    - Linux: 소스 파일을 가져와서 직접 컴파일, 링크하여 라이브러리를 이진 파일로 만들기
  
  - www.opencv.org > Release > .exe 파일 실행하기
  - OpenCV를 다운로드한 위치를 확인하기(이 경로를 알고 있어야 환경설정할 때 편함)
  
  - VS 프로젝트 설정하기
    - 각 프로젝트 별로 Project 새로 생성 후
    - Visual Studio의 구성(Configuration)을 x64 플랫폼으로 설정하기
    - Visual Studio의 속성에서 openCV 헤더파일 경로 설정하기
    - Visual Studio의 OpenCV 라이브러리 경로 및 파일명 설정하기
  
  - Visual Studio의 New project 생성
    - Windows 데스크톱 마법사 > 콘솔 애플리케이션 > 빈 프로젝트
  
  - Visual Studio 프로젝트 구성 설정(1)
    - Configuration(구성) 바꾸어 x64 플랫폼으로 설정하기
  
  - Visual Studio 프로젝트 구성 설정(2)
    - 구성 관리자에서, Debug 구성 및 x64 플랫폼으로 설정하기
    - 또는 빌드 > 구성관리자 메뉴에서 변경
  
  - Visual Studio 프로젝트 속성 설정
    - 헤더파일 경로 설정
      - 프로젝트 > 속성 > C++ > 일반 > "추가 포함 디렉터리"에 다음 2줄 추가
      - C:\opencv\build\include
      - C:\opencv\build\include\opencv2
      - 추가한 뒤에 "적용"
  
    - 추가 라이브러리 디렉터리 설정
      - 속성 > 링커 > 일반 > 추가 라이브러리 디렉터리에 다음줄 추가하고 "적용"
      - C:\opencv\build\x64\vc15\lib
  
    - 추가 종속성 설정
      - 속성 > 링커 > 입력 > 추가 종속성에 다음 줄을 추가하고 "적용"
      - opencv_world452.lib
      - opencv_world452d.lib
      * 위 두개의 라이브러리 파일을 같은 구성에 모두 추가하면 안됨!
  
    - 디버깅 환경 설정
      - 구성 속성 > 디버깅 > 환경에 다음 줄을 추가하고 "적용"
      - PATH 설정
  
    - 확인하기: New 소스 file 생성(소스.cpp)
      - 솔루션 탐색기 > 프로젝트 선택 후 마우스 우클릭 > 추가 > 새항목
      - 또는 프로젝트 > 새항목추가
  
- Visual Studio에서 OpenCV 샘플 코드 실습
  
- 기본 자료구조(Mat) 및 픽셀접근
  - Mat
    - openCV에서 가장 중요한 자료구조
    - 하나의 Image를 표현하는 자료 구조
    - Mat Class의 Object에 이미지를 저장함
    - 헤더(이미지의 기본 정보: 해상도(가로x세로), 채널의 개수(1개이면 gray, 3개이면 color))
    - 바디(픽셀의 정보) -> 헤더가 포인터로 바디를 가리킴
    - =로 복사하면 헤더만 복사되기 때문에 .clone()이라는 함수를 사용해서 바디 정보까지 복사함
    - 바디에는 Width(column)과 Height(rows)가 들어감
    - openCV에서는 RGB가 아니라 BGR 순서로 저장됨
  
  - 헤더에 저장되는 형태는 CV_<DataType>C<Channel>
    - ex: CV_8UC3, CV_32FC3, CV_8UC1
    
  - Mat M;
  - Mat M(rows, colums, pixel_type);
  - Mat M(rows, colums, pixel_type, initial_value);
    - initial_value: 칼라값 지정
      - ex: Scalar(0,0,255)
  
  - Mat M(SIZE(width, height), pixel_type, initial_value);
    - size로 하면 width, height 순서임
  
  - 내부값 Access
    - Mat.type(): 데이터 타입에 해당하는 상수값
    - Mat.depth(): 바이트 개수(픽셀 하나 당 몇 byte로 구성되었는지 숫자로 리턴)
    - Mat.at(row, column)[channel]: 하나하나의 픽셀을 엑세스(return type을 channel로 지정해줘야 함)
      - ex: channel: <Vec3b>
  
  - Size of Mat data matrix(bits): #columns * #rows * #channels # channel depth
  - M.elemSize1(): 한 픽셀의 채널 당 비트수
    - M.depth()
  - M.elemSize(): 한 픽셀 당(채널수 * 채널당 비트수)

  - MAT Data 메모리 공유, 복사하기
    - 아래 두가지 방식으로 하면 바디는 복사되지 않고, 헤더만 복사됨(shallow copy)
      - Mat dst = src;
      - Mat dst(src)
    - col와 row를 명시해주면 기억장소까지 복사됨
    - 기억장치 모두 복사하고 싶을 때(deep copy)
      - .clone()
      - copyTo()
  
- 입출력 및 그리기
  - 이미지 파일을 읽어서 그리기
    - Mat img1 = imread("foo.png". IMREAD_COLOR)
      - IMREAD_COLOR: 0(gray), 1(color)
      - imread의 return 값은 Mat 타입
      - 파일의 경로에 이름만 쓰면 상대경로(path의 시작에서는 mac에서는 환경설정, windows의 vs에서는 프로젝트의 경로가 시작점)
      - 파일의 확장자를 통해서 이미지 양식을 읽어옴(여러가지 양식 가능)
  
    - imwrite로 저장 가능
    - namedWindow로 윈도우 생성 가능
    - imshow로 화면에 출력 -> waitKey(0): 무한대로 기다리는 코드를 써줌(0은 무한대, 다른 숫자도 가능)
    - destroyWindow로 만들어진 윈도우 종료
    - destroyAllWindow 모든 윈도우 종료
    - 동영상 파일은 1초에 20~30개의 정지영상
    - cv::waitKey(33): 초당 33개의 이미지를 불러온다는 뜻
  
  - 그림을 그리는 함수
    - drawing line
      - cv::line(Mat &img, Point pt1, Point py2, Scalar & color, int thickness)
      - cv::arrowedLine(Mat &img, Point pt1, Point py2, Scalar & color, int thickness)
  
    - drawing box
      - cv::rectangle(Mat &img, Point &pt1, Point &pt2, Scalar &color, int thickness=1)
        - thickness를 -1로 하면 내부를 채워줌
      - cv::rectangle(Mat &img, Rect rect, Scalar &color, int thickness=1)
  
    - drawing circle
      - circle(Mat &img, Point &center, int radius, Scalar &color, int thickness=1)
  
    - drawing text
      - cv::putText(Mat &img, String &text, Point org, int fontFace, double Scale, Scalar color, int thinkness)
  
- 컬러 변환 및 영상 채널 분리
  - Color space conversion
    - cvtColor(input_img, output_img, flags)
      - flags
        - COLOR_BGR2GRAYSCLE
        - COLOR_BGR2YUV
        - COLOR_BRG2HSV
        - COLOR_GRAY2BGR
          - color에서 grayscale은 가능하지만 반대로는 안됨(채널 1개에서 3개로 늘어나는 것, 원래 gray의 채널을 3개로 복사하는 것)

        - COLOR_BGR2RGB
  
    - imshow에서 채널이 1개면 grayscale, 3개면 bgr로 나타내기 때문에 HSV나 YUV를 imshow로 출력하면 이상한 값이 출력될 수 있음
  
  - Mat의 채널 분리 및 병합
    - split(Mat, vector<Mat>)
      - 3채널에서 싱글채널 3개의 이미지로 분할함
      
    - merge(vector<Mat>, Mat)
      - 싱글채널 이미지 3개를 BGR 이미지 1개로 합쳐줌
  
  - ROI(기존 Matrix의 일부로 sub Matrix 나타내기)
    - Mat M(Mat, Rect);
    - Mat M(Mat, Rect(30, 60, 200, 400))
    - Mat M(Mat, Rect(Point(230, 60), Point(430, 460))
      - M을 만들때, 사각형(영역)을 변수로 넣어줌)
  
    - 원본 이미지와 데이터를 공유하기 때문에 하나의 값을 바꾸면 모두 변화함
  
- 노이즈 제거
  - Image Filtering(=Smoothing)
    - 원래 이미지에 고유한 값이 아니라 다른 노이즈가 들어있을 수 있음
    - 노이즈는 원래 값이 아닌 값을 뜻함
    - 자연상태의 값은 점진적으로 변하고 주변과 비슷한 이미지를 갖음
    - (x, y)에서 노이즈를 완화하기 위해서는 필터를 씌움
    - (x, y) 주변에 있는 8개 또는 더 많은 픽셀들을 이용해서 더 많은 값을 이용해서 재정의함
    - 주변 9개의 평균을 구해서 값 변화화는 과정에서 노이즈라면 굉장히 완화된 값으로 변화함
    - 위와 같은 과정이 스무딩, 블러링이라고 표현함
    - 필터의 계산을 Convolution 연산한다고 표현

  - blur = mean filter라고 부름
  - GaussianBlur: 평균을 구할 때, 웨이트를 거리에 따라서 차등으로 주어짐(가우시안 분포와 같은 그림), 가운데일 수록 높게
  - medianBlur: 평균값이 아닌 sorting 해서 중간 값으로 계산
  - bilateralFilter: 물체의 경계선이라고 생각하는 부분(Edge)은 필터 적용을 하지 않고 나머지 부분은 가우시안 필터 적용(경계선이 확실하게 구분됨)
  
- 이진화
  - 이진화
    - 영상의 픽셀값들을 기준값 이상과 미만의 두가지로 나누고 픽셀값을 분류결과에 따라 재설정함
    - 보통 블랙(0)은 관심이 없는 영역, 화이트(255)는 관심 영역으로 추출함

  - 단일 문턱치 처리
    - 어두운 배경으로 밝은 객체로 구성된 영상이 있는 경우
    - 객체를 추출하는 방법은 문턱치를 활용하는 것임
    - 보통은 grayscale 이미지를 이진화 처리함
      
    - t(문턱치)를 구하는 방법
      - 전역적 문턱치: 영상 전체에서 하나의 문턱치 값을 적용
        - Threshold(input_image, output_image, threshold_value, max_val, threshold_type)
          - threshold_type
            - THRESHOLD_BINARY: 대표적인 방법
            - THRESHOLD_BINARY_INV: THRESHOLD_BINARY 결과를 반전시킴
            - THRESHOLD_TRUNC: 입력값이 threshold_value를 초과하면 threshold_value로 만들고 그 이하는 원래값을 그대로 유지함
            - THRESHOLD_TOZERO: 입력값이 threshold_value 이하이면 0으로 만들고, 초과이면 그대로 원래값을 유지함
            - THRESHOLD_TOZERO_INV: THRESHOLD_TOZERO를 반전시킴
            - THRESHOLD_OTSU: 영상 전체 히스토그램에서 두개의 peak를 구분하는 threshold값을 찾음
              - 전제, 전체의 이미지의 히스토그램에서 2개의 봉우리가 생김, 픽셀값들이 2개의 그룹으로 나뉘어질 때만 가능
              - 2개의 peak 값으로 잘 나눠질 경우에 적용(반대로 두 개의 피크값으로 나눠지지 않는다면 이상한 결과가 나올 수 있음)
  
      - 가변적 문턱치: 영상 내에서 각 영역에 따라 문턱치 값을 다르게 적용
        - adaptiveThreshold(input, output, max_value, adaptive_threshold_type, threshold_type, ksize, C)
          - 자기 자신을 둘러싼 픽셀의 평균값을 기준으로 평균값이 Threshold로 지정
          - 위의 과정은 너무 단순하니까 평균값에서 상수 C를 뺀 값으로 Threshold로 지정
          - 평균을 구하는 과정도 단순 평균과 가우시안 방법이 있음
  
  - COLOR 범위에 의한 이진화: inRange 함수
    - 두 개의 threshold를 지정함
    - cv2::inRange(Mat &src, inputArray lowerb, inputArray upperb, Mat & dst)
      - ex) inRange(img, Scalar(50, 100, 50), Scalar(80, 255, 255), green)
  
- 모폴로지 연산
  - 이진 영상을 입력으로 받아서 이진 영상을 출력으로 받음
  - 연산의 대상과 커널이 존재
  - 이 커널을 대상의 한 픽셀씩 움직이면서 하나라도 0이 있으면 가운데 픽셀값을 0으로 만드는 과정이 침식(AND 연산)
  - 반대로 하얀색 영역이 하나라도 있으면 하얀색으로 만드는 과정이 팽창(OR 연산)
  
  - 침식(Erosion), 팽창(Dilation)
    - dilate(src, dst, kernel, anchor, iterations, borderType, borderValue)
    - erode(src, dst, kernel, anchor, iterations, borderType, borderValue)
      - kernel
        - getStructuringElement 함수로 kernel 만들어서 사용할 수 있음
        
      - iteration: 몇 번 반복할 것인지
  
  - Opening & Closing
    - Opening
      - 침식 > 팽창
      - block dot noise 제거 용이
      
    - Closing
      - 팽창 > 침식
      - white dot noise 제거 용이
  
  - MORPHOLOGICAL OPERATION
    - morphologyEx(src, dst, op, kernel, anchor, iterations, borderType, borderValue)
      - op: type of a morphological operation
        - CV_MOP_OPEN
        - CV_MOP_CLOSE
  
- 에치 검출
  - Edge
    - 영상에서 밝기가 급격하게 변하는 화소
    - 엣지로 검출되는 영역이 대체 물체의 경계선의 후보 또는 노이즈
    
  - Edge type
    - 계단 엣지: 1화소 거리에서 이상적으로 일어나는 엣지
    - 비탈 엣지: 일반적인 디지털 영상은 무뎌지고 노이즈가 낀 엣지
    - 지붕 엣지: 영역을 지나는 선에 대한 모델
  
  - 엣지를 찾는 방법
    - 픽셀 값의 변화를 통해서 찾음
    - 차이값이 바로 미분을 하는 개념
    - 디지털 세계에서 미분값은 뺄셈과 동일(옆의 픽셀과 빼는 것)
    - 빼는 과정이 3가지
      - Forward difference: 본인을 기준으로 이후 값을 뺌
      - Backward difference: 본인을 기준으로 이전 값을 뺌
      - Central difference: 본인을 기준에서 이후 값에서 이전 값을 뺀 값
        - 컨볼루션 연산 기준에서 수평방향(왼쪽 1, 가운데 0, 오른쪽 -1) / 수직방향(위 1, 가운데 0, 오른쪽 -1)
  
  - Sobel Filter
    - 가까이 있는 것은 더 많은 가중치를 주는 것
    - Sobel(input, output, ddepth, dx, dy, ksize, scale, delta, border)
      - ddepth: output의 depth(0을 두면 기본값)
      - dx, dy: 0: x방향으로 미분, 1: y방향으로 미분, 2: 2차미분
      - scale, delta: 빼준 것에서 얼마를 곱해줄 것인가
  
  - Canny Edge Detector
    - 에지를 구하기(입력은 grayscale)
    - 수평방향과 수직방향의 필터를 적용하게 되면 gradient와 magnitude를 알 수 있음
    - threshold로 이진 영상을 만들기
    - Non-Maximum Suppression
      - 각 픽셀의 gradient가 얻어지면 그 방향과 같은 gradient를 가진 인접 픽셀들의 gradeint magnitude들과 비교하여 가장 크기가 큰 픽셀만 에지로 남김
      - blur한 영역의 에지들을 제거하는 효과를 가짐
      
    - Double Threshold
      - 이미지의 노이즈로 인해서 나타난 false positive들(에지로 인식되었으나 사실은 에지가 아닌 픽셀들)을 제거함
      - 각 픽셀의 gradient magnitude가 high threshold보다 크면 strong edge로 분류함
      - 각 픽셀의 gradient magnitude가 low threshold보다 작으면 제거함
      - 각 픽셀의 gradient magnitudue가 high와 low threshold 사이에 있으면, weak edge로 분류함
      - weak edge는 인접한 8개의 pixel이 strong edge일때만 최종적으로 strong edge로 분류됨
  
    - Canny(input, output, threshold1, threshold2, ksize)
      - threshold 2개를 잘 조절하는 것이 좋음
  
- 직선 검출
  - Hough Line 변환의 필요성
    - 영상에서 에지 추출 후 에지 정보를 연결하여 관심 정보(직선) 추출
    - 관심 객체에 대한 정보 없이 추출이 어려움
    - y = ax + b로 만들어서 직선의 식을 찾는것은 y가 0일 때의 문제점이 발생함(기울기가 무한대)
    - r세타 평면의 활용하면 a, b 평면에서 표현
    - 만나는 두 점을 지나는 r과 세타를 이용하면 직선을 찾을 수 있음
    - 여기서 r과 세타에서 어느 오차를 허용해줘야 함(앵글을 몇도 단위로 나눠서 같은 단위로 볼 것인지 정해야 함, 그래프의 해상도를 얼마로 해야 하는지)
    - 몇 개의 edge가 지나야 직선으로 볼 것인지 기준이 있어야 함
  
  - Hough Line 알고리즘
    - Grayscale 영상 변환
    - 엣지 영상 획득
    - r세타 평면에서 구획 지정(간격, 몇개)
    - 엣지를 이루는 점들에 대해서 각각 r, 세타 계산하여 각 구획에 vote
    - 문턱값 이상의 vote를 받은 구간에서의 r, 세타 값을 직선으로 간주
  
  - HoughLinesP(input, output, rho, theta, threshold, minLineLength = 0, maxLineGap = 0)
    - output: 직선의 정보(직선을 구하는 것이 아닌 직선의 성분(직선을 이루는 양끝점의 좌표) = 포인터의 벡터의 벡터
    - rho: rho 세타 평면에서의 격자의 간격(픽셀을 기본 단위로 한 각도)
    - theta: 라디안 값
    - threshold: 한 격자의 몇 개의 vote를 받으면 직선으로 보겠냐는 기준값(듬성듬성 있더라도 edge의 픽셀 개수가 threshold만큼 있어야 함)
    - minLineLength: 직선이라면 적어도 얼마 이상의 길이
    - maxLineGap: 직선을 검출 과정에서 노이즈때문에 끊기는 것을 몇 개의 직선으로 볼 것인지(maxLineGap보다 작은 edge는 하나의 직선으로 봄)
    - threshold 값을 높여서 검출하면 정확도도 늘어나지만 미검출도 늘어나고, threshold 값을 낮추면 검출되는 것도 많아지고 오검출(노이즈 검출)도 많아짐)

- 다각형 검출
  - 윤곽선(Contour) 검출
    - findContours(image, contours, hierarchy, mode, method, offset): 점을 모아서 다각형 윤곽선 정보로 변환
    - image: edge image(8bit single_channel)
    - contours: 윤곽선을 형성하는 점들의 집합
    - hierarchy: 윤곽선의 자료 구조
      - 점 4개의 집합
      - <vector>의 <vector>
        - [i][0]=next
        - [i][1]=prev
        - [i][2]=first child
        - [i][3]=parent
        - Array에서 표현하기 때문에 index number
        - 자식 계층 구조가 없으면 index number가 -1
      
    - mode: 윤곽선을 찾을 때 모든 엣지들을 윤곽선에 담을지, 중요한 엣지만 담을지 선택하는 모드
      - CV_RETR_EXTERNAL: 최외곽 1개 추출
      - CV_RETR_LIST: 계층 구조를 찾지 않고 모두 열거
      - CV_RETR_CCOMP: depth가 2개인 트리 구조로 인식하고 계층 구조를 만들어줌(완벽 트리 구현해줌)
      - CV_RETR_TREE: 모든 계층 구조 트리로 인식해줌
  
    - method
      - CV_CHAIN_APPROX_SIMPLE: 엣지들이 직선으로 나오지 않을 수 있는데 countour 정보에 생략(꼭지점만)
      - CV_CHAIN_APPROX_NONE: 엣지들이 직선으로 나오지 않을 수 있는데 countour 정보에 생략하지 않고 모두 담기
  
    - findContours의 output은 원본 이미지가 달라짐, 그러므로 원본을 copy해서 사용하는 것 추천
  
  - 찾은 윤곽선 구하기
    - drawContours(image, contours, contourIdx, color, thickness, hierarchy, maxLevel, offset): findContours 에서 찾은 Contour를 그려줌
      - drawContours 한 번 실행마다 vector<vector<Point>>안에서 <vector<Point>>에 따른 Contour를 한번씩 draw를 실행
      - contourIdx: 몇 번째 contour를 그릴 것인지
  
  - 다각형으로 근사화
    - approxPolyDP(curve, approxCurve, epsilon, closed): 삐뚤게 나온 contour들을 다격혀응로 근사화(findContours의 결과를 입력으로 사용)
    - curve: vector<Point>
    - epsilon: 얼마나 곱게 필건가에 대한 값(0이면 원래 입력과 똑같음, 커질수록 더 다각형이 근사화되게 만들어짐)
    - 간단하게 부터 복잡한 순서로 알고리즘 구성(가장 먼 두점을 이어준 다음에 두 점을 이은 직선에서 수직에서 내린 선들 중에 epsilon보다 작은 거리는 무시하고 큰 거리는 남기는 과정을 반복)

- 차선인식 예제
  - ROI 설정하여 영상자르기
  - 노이즈 제거(가우시안 빌터, mean 필터, Bilater 필터)
  - 컬러공간 변환(차선은 흰색(밝기정보만 필요하기 때문에 grayscale)과 노란색(hsv)을 찾아냄)
    - opencv는 BGR에서 HSV로 변환할 때 8bit를 사용하기 때문에 H의 최대 크기가 255, 하지만 H의 최대값은 360이기 때문에 OpenCV에서는 2로 나눠서 최대값을 180으로 사용
  - 이진화(색상정보 또는 밝기 정보)
  - 에지 검출(Canny)
  - 직선 검출(Hough)
    - 일정한 각도안에 들어오고나 좌우 대칭을 이용해서 차선 구분
    - 짧은 선 제외(HoughLinesP의 MinLength 사용)
    - 직선의 각도 고려
    - 인접 직선의 통합
    - ROI 설정하여 연산 속도 증가 및 노이즈 배제
  - 차선 판정
  - 차선 그리기
  
  - 하나의 threshold로 고정해서 하기엔 어려움(frame이나 영역마다 threshold 바꿔주기)
  - 차선이 인식이 잘 되지 않는다면 시간적으로 축적된 정보도 활용해서 사용해보기(동영상은 여러 프레임으로 구성되기 때문에)