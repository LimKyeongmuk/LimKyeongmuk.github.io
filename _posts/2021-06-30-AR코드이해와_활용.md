---
title: "AR 코드 이해와 활용"
excerpt: ""

categories:
  - AR 코드
tags:
  - AR 코드
---
### AR Tag 소개와 설치
- AR TAG 소개
  - 증강현실에서 사용하는 Tag
  - AR Tag를 이용하여 현실의 물체를 가상환경에 대입하는 것이 가능
  - AR Tag가 인쇄된 종이를 인식하고 그로부터 얻은 데이터를 이용하여 자신 또는 대상 물체의 위치와 자세를 파악할 수 있음
  
- 증강현실
  - 카메라로 촬영한 영상에서 컴퓨터 그래픽을 통해서 증강시킨 것
  - 우리가 보는 것은 3차원, 촬영된 영상 또는 사진은 2차원
  
- AR Tag Tracking 활용
  - 검은색 바탕의 흰색 모양의 각각이 다른 모양으로 각 태그들은 구분이 가능(고유의 번호를 가짐)
  - roll, pitch, yaw 표현 가능
  - rviz 시각화 가능
  - 어느방향으로 기울어졌는지 정육면체로 표현 가능
  - Demo of April Tag Localization System
    - https://www.youtube.com/watch?v=Y8WEGGbLWIA  
  - 교통 표지판(자세나 위치보다 구분하는 용도)
  - 주차 가이드 표시(자율주행 자동차가 똑바로 주차하는 것이 가능)
  - ar_tack_alvar(QR코드나 바코드는 전세계 규격이지만 ar tag는 그런 규격이 없지만 ROS 환경에서 많이 사용되는 패키지)
  
- AR Tag 패키지 설치
  - $ sudo apt install ros-melodic-ar-track-alvar
  - 설치되는 위치: /opt/ros/melodic/share/ar_track_alvar
  
### AR Tag 실행 테스트(AR Tag 뷰어 실행을 위한 패키지 생성과 launch 파일 제작)
- 패키지 생성
  - ar_viewer 패키지 만들기
  
- launch 파일 살펴보기
  - 예시 launch 파일 살펴보기
    - $ cd /opt/ros/melodic/shar/ar_track_alvar/launch/
    - 많은 launch 파일들이 있지만 Kinect 장비를 사용하지 않고 단일 태그만을 인식하는 pr2_indiv_no_kinect.launch 파일 복사해서 사용
    - kinect: 동작 인식을 위해 MicroSoft에서 개발한 카메라 장치  
  - pr2_indiv_no_kinect.launch 파일의 내용 중에서
    - marker_size 항목에는 사용할 AR Tag의 사이즈가 들어가야 함(우리가 사용할 태그는 크기가 9.0cm)
    - cam_image_topic 항목에는 카메라 영상을 담은 토픽 이름이 들어가야 함(usb_cam 패키지를 사용하고 있으므로 /usb_cam/image_raw가 들어가야 함)
    - cam_info_topic 항목에는 카메라 영상을 담은 토픽 이름이 들어가야 함(usb_cam 패키지를 사용하고 있으므로 /usb_cam/camera_info가 들어가야 함)
    - output_frame 항목에는 카메라 노드의 frame id가 들어가야 함(usb_cam 패키지를 사용하고 있으므로 "head_camera"가 기본값임, RVIZ에서 사용하면 "map" 값으로 설정)
  - pr2_indiv_no_kinect.launch 파일을 복사해서 ar_viewer.launch 파일 만들기
    - marker_size 값은 9.0으로, output_frame 값은 "map"으로 변경
  
### 카메라 캘리브레이션(AR Tag 실행할 때 카메라 설정에 의한 외곡 현상을 피하기 위핸 재설정 작업)
- 카메라 캘리브레이션
  - 우리가 실제 눈으로 보는 세상은 3차원
  - 그런데 이것을 카메라로 찍으면 2차원의 이미지로 변하게 됨
  - 이 때, 3차원의 점들이 이미지 상에서 어디에 맺칳는지 (기하학적으로 생각하면) 영상을 찍을 당시의 카ㅏ메라의 위치 및 방향에 의해 결정됨
  - 하지만 실제 이미지는 사용된 렌즈, 렌즈와 이미지 센서와의 거리, 렌즈와 이미지 센서가 이루는 각 등 카메라 내부의 기구적인 부분에 의해서 영향을 받아 왜곡됨
  - 따라서, 3차원 점들이 영상에 투영된 위치를 구하거나 역으로 영상 좌표로부터 3차원 공간좌표를 복원할 때에는 이러한 내부 요인을 제거해야만 정확한 계산 결과가 나옴
  - 이러한 내부 요인의 파라미터 값을 구하는 과정을 카메라 캘리브레이션이라고 함
  - 캘리브레이션으로 재설정해야 하는 중요한 카메라 내부 파라미터들
    - 초점 거리(focal length)
    - 주점(principal point)
    - 비대칭 계수(skew coefficient)
  
- Calibration을 위한 이미지 출력
  - 아래 링크에서 체스 그림을 담은 pdf 파일을 다운로드해서 프린트
    - http://wiki.ros.org/camera_calibration/Tutorials/MonocularCalibration?action=AttachFile&do=get&target=check-108.pdf
  - 해당 pdf 파일의 원본 크기는 체스 무늬의 정사각형 한 변의 길이가 10.8cm로 매우 크므로 인쇄할 때 페이지 맞춤으로 설정해서 A4 한 장에 출력하기
  
- Calibration을 위한 카메라 노드 실행
  - $ roslaunch usb_cam usb_cam-test.launch
  
- Calibration을 위한 명령 실행
  - $ rosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.025 image:=/usb_cam/image_raw camera:=/usb_cam
  - 출력된 종이에서 사각형의 한 변의 길이를 실제로 정확하게 재서 미터 단위로 변경해서 입력
  - 성공적인 프로그램 실행 화면: 카메라 영상과 함께 우측에 동그란 버튼 3개가 표시되는 창
  
- Calibration 작업 진행
  - 우측 상단 X, Y 게이지가 녹색이 될 때까지 체스 무늬 종이를 계속 움직이기
  - 우측 상단 X, Y 게이지가 가득 차면 'CALIBRATE' 버튼이 활성화되고, 버튼을 누르면 Calibration 작업이 시작
  
- Calibration 결과 저장
  - 'SAVE' 버튼이 활성화되면 해당 버튼을 눌러 Calibration 결과를 저장
  - /tmp 폴더에 calibrationdata.tar.gz 파일이 만들어짐
  
- Calibration 결과 파일
  - /tmp 폴더에 calibrationdata.tar.gz 파일에서 ost.yaml 파일을 꺼내서 ar_viewer/calibration 디렉토리로 옮기기
  
- 카메라 Calibration 파라미터 수정
  - ost.yaml 파일의 이름을 usb_cam.yaml로 변경
  - 세번째 줄에서 camera_name 값을 usb_cam으로 변경
  
- usb_cam.yaml
  - 여기에 있는 숫자들이 값이 Calibration 작업으로 얻어진 보정값이며 이 값은 각자의 카메라 제품에 따라 다른 수치를 갖음

### RVIZ 뷰어 설정(AR Tag 정보 시각화)
- RVIZ 뷰어 설정
  - 런치 파일 실행
    - $ roslaunch ar_viewer ar_viewer.launch  
  - 아직 설정 정보가 없어서 RVIZ 화면에 아무것도 표시되지 않음
    - 데이터를 표시할 뷰어 컴포넌트 3개 추가
    - 몇 개 파라미터 값 설정
    - Ctrl-S 눌러서 설정 값 Save(ar_viewer.rviz)
  
- AR Tag 준비
  - $ rosrun ar_track_alvar createMarker
  - 또는 ROS 사이트에서 이미 완성된 그림 파일 다운
  
- AR Tag 인식 프로그램 실행
  - $ roslaunch ar_viewer ar_viewer.launch
  - usb_cam 노드 실행
  - ar_track_alvar 노드 실행
  - rviz_repub 노드 실행
  - rviz 노드 실행
  
- RVIZ 뷰어 실행 화면
  - 카메라 영상과 함께 가상 공간에 AR Tag의 위치와 방향(자세) 표시

### AR Tracker가 발생하는 토픽 구독 응용
- AR Tag 정보를 추출해서 화면에 출력
  - 노드
    - /usb/cam()
    - /ar_track_alvar(토픽 /ar_pose_marker)
    - /ar_info_print
  
- ROS 노드와 토픽 리스트 확인
  - $ roslaunch ar_viewer ar_viewer.launch
  - $ rosnode list
  - $ rostopic list
  
- /ar_pose_marker 토픽 내용 살펴보기
  - $ rostopic echo /ar_pose_marker
  - 헤더 정보
  - 인식된 AR Tag의 위치 정보(3차원 벡터 값)
  - 인식된 AR Tag의 방향(자세) 정보(쿼터니언 값)
  
  - $ rosmsg info ar_track_alvar_msgs/AlvarMarker
  
- 구독자 파이썬 코드: ar_info_print.py
  - AR_TRACK_ALVAR가 발행하는 ar_pose_marker 토픽을 구독해서 안에 담긴 정보를 추출하여 화면에 출력함
  
- 실행하기
  - $ roslaunch ar_viewer ar_viewer.launch
  - $ rosrun ar_viewer ar_info_print.py
  
- x, y, z 값
  - x: 왼쪽 - 오른쪽 +
  - y: 왼쪽 - 오른쪽 +
  - z: 가까우면 적게 멀면 크게
  
- Roll, Pitch, Yaw
  - 자세 정보(카메라 화면 기준으로)  
  - 숙이면 roll 증가, 젖히면 roll 감소
  - 위에서 시계방향 ptich 증가, 반시계방향 pitch 감소
  - 시계방향 yaw 증가, 반시계방향 yaw 감소(축을 위에서 봤을때 반시계방향이 증가하는 방향)

### AR Tag 위치 표시
- AR Tag의 위치를 파악해서 시각화하는 뷰어 제작
  - AR Tag가 차량의 좌우 어디쯤 있는지, 얼마만큼 떨어져 있는지를 파악하기 위한 목적
  - OpenCV를 이용하여 시뮬레이터에 있는 자동차 관점에서 AR 위치와 거리를 다음과 같은 형태로 표시
  
- 작업 디렉토리
  - ar_viewer 패키지
  
- 런치파일 만들기
  - ar_drive.launch
  
### AR 태그로 주차하기
- Xycar Parking Simulator 환경에서 수행하기
  - 자동차는 가승 AR Tag를 보고 주행하여 주차구역 안에 주차하기
  - 차가 주차구역 안에 완전히 들어갔을 때 주차구역 선이 녹색으로 바뀜
  
- Xycar Parking Simulator로부터 AR 태그 정보 입수
  - 차와 움직임을 같이하는 좌우 빨간 선 한쌍은 시뮬레이터 속 가상의 카메라 범위를 의미
  - 가상의 카메라 시야 각 안에 AR Tag(녹색 표시)가 존재하면 /ar_pose_marker 토픽에 AR Tag의 위치와 자세 정보가 담겨 publish
  
- AR 태그의 자세 정보를 이용
  - AR 태그가 카메라 시야각 안에 들어오면 (영상처리를 통해 추출된) 정보가 발행됨
  - 추출된 자세 정보는 /ar_pose_marker 토픽에 담겨 발행
  - 이 정보를 이용해서 주차영역으로 진입
  
- 작업 폴더
  - 기존에 만든 ar_viewer 폴더
  
- 런치파일 만들기
  - ar_parking.launch
  
- 시뮬레이터가 보내는 토픽
  - /ar_pose_marker
    - 3차원 공간에서의 좌표값(x, y, z)
      - pose.pose.position (x, y ,z)
      - 픽셀 단위의 거리 정보(실제로는 m)  
    - 자세 정보값(Roll, Pitch, Yaw)
      - pose.pose.orientation(x, y, z, w)
  
- 자동차 자세 잡기
  - AR Tag 자세를 보고 자동차의 자세를 잡기
  - AT Tag까지의 거리를 따져서 핸들링 하기
  - angle = tan-1(y거리/x거리)
  - 차량의 왼쪽과 오른쪽 구분
  
- 주차를 위한 자동차 제어
  - 똑같은 거리지만 다른 자세(Yaw)
  
- 비스듬히 주차한 경우
  - 후진해서 다시 주차 시도