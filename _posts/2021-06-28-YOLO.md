---
title: "YOLO"
excerpt: ""

categories:
  - YOLO
tags:
  - YOLO
---
### Object Detection
- Classification
  - 객체가 무엇인지 알아내는 문제  
  
- Object Detection
  - 하나의 이미지 내부에 존재하는 다수의 객체를 파악하고 객체의 각각의 위치에 bounding box를 그려주고
  - 각 bounding box 내부의 대상을 분류하는 문제
  - 위치 검출 + 객체 분류
  - 최근에 딥러닝 기술 결합되며 속도와 정확도가 크게 증가
  
- 딥러닝 기반 Object Detection 종류
  - Two-shot Detection
    - 먼저 객체의 위치 검출 후 분류 수행
    - 일반적으로 연산 시간이 길지만 정확도가 높음
    - 관련 기법: R-CNN, F-CNN, R-FCN, FPN-FRCN, Fast R-CNN

  - One-shot
    - 객체의 위치 검출과 분류를 동시에 수행
    - 일반적으로 연산이 빠르지만 정확도가 낮음
    - 관련 기법: YOLO, SSD, RetinaNet
  
- YOLO
  - 논문: You Only Look Once:Unified, Real-Time Object Detection(2016)
  - Facebook AI Reserach
  - Version1(2016), Version2(2017), Version3(2018), Version4, Version5, PP-YOLO(2020)
  
- YOLO v1
  - 특징: 한번 보는 것만으로 객체의 위치 검출과 분류 수행(only look once)
  - 장점
    - 간단한 처리과정으로 속도가 매우 빠름
    - 낮은 background error를 보임
    - 객체에 대해 일반화된 특징을 학습(실제 사람 사진으로 학습하고 그림을 보여줘도 사람으로 인지)  
  - 단점
    - 상대적으로 낮은 정확도(특히 작은 물체에 취약)
  
- YOLO Network
  - 이미지를 입력으로 하며 네트워크를 통과하면 중앙 2개의 결과를 얻음
  - 이미지를 S x S 그리드로 나눠줌
  - Bounding box + Confidence
    - 각 그리드마다 경계 박스를 2개씩 생성
    - 경계 박스 안쪽에 객체가 있다는 확신이 높을수록 진하게 표시
    - 굵은 경계 박스들은 남기고 얇은 박스들은 지워줌  
  - Class Probability Map
    - 각 그리드가 어떤 대상인지 분류  
  - 위의 결과들을 종합하여 객체의 위치 검출과 객체에 대한 분류 수행
  - 네트워크 구조
    - GoogLeNet 모델 기반
    - 24개의 Conv, 2개의 FC Layer
    - 최종적으로 7x7x30 크기를 가지는 결과 도출  
  - Output
    - 7x7은 Grid cell을 의미, 30 = 5 * Grid당 bounding box의 수(2) * 분류할 클래스의 수(20)
    - 각 Bounding box(bbox)가 가지는 값
      - x: bbox 중앙의 x 좌표
      - y: bbox 중앙의 y 좌표
      - w: bbox의 너비
      - h: bbox의 높이
      - c: 확신의 정도  
    - 30개 중 처음 10개는 1번째와 2번째 bbox를 구성하는 값들
    - 20개는 분류를 위한 class의 수(각 class에 대한 확률 값을 가짐)
  - 손실함수
    - 총 5개의 손실 함수 사용
    - 객체가 존재하는 grid에서 bbox의 x, y 위치에 대한 손실함수
    - 객체가 존재하는 grid에서 bbox의 w, h에 대한 손실함수
    - 객체가 존재하는 grid에서 bbox의 confidence score에 대한 손실함수
      - 실제 객체가 존재할 확률을 0~1로 나타냄  
    - 객체가 존재하지 않는 grid에서 confidence score에 대한 손실함수
      - 객체가 없는 경우 0에 가깝게  
    - 객체가 존재하는 grid에서 분류 클래스 확률에 대한 손실함수
      - 객체가 어떤 대상인지 분류  
  - YOLO 결과
    - Real-time Detector 중 높은 정확도 -> mAP(Mean Average Precision)
    - Fast YOLO의 경우 가장 빠른 연산 수행 -> FPS(Frame Per Second)
    - Fast R-CNN에 비해 정확도(Correct)는 낮지만 Background error가 낮은 것을 확인할 수 있음
    - 일반화된 특징을 학습하여 실제 이미지를 통해 학습 후 예술품이나 인터넷에서 찾은 랜덤한 이미지에 적용해도 좋은 결과를 보임
  
### YOLO 실습
- 설치 및 예제 실행
  - YOLO Linux 빌드 및 실행
    - Alexey YOLO
      - Original YOLO는 pjreddie의 yolo였으나, 자신의 YOLO가 전쟁 등에 사용되는 것을 보고, 더 이상 YOLO를 개발하지 않겠다고 선언
      - 그 후로 Alexey가 이어받아서 Bug Fix와 릴리즈를 하고 있음
      - Pjreddie의 YOLO와 달리 Alexey는 Windows 또한 지원하며 Alexey만의 yolov4 버전을 출시
  
    - Alexey YOLO 설치 방법 (Linux)
      - Alexey YOLO를 리눅스에 설치하기 위해서는 ROS Kinetic(16.04) 또는 ROS Melodic(18.04)가 설치되어있어야 함
        - ROS가 설치되어 있지 않다면 디팬던시를 충족하는 각각 패키지를 모두 설치해야 함  
      - Alexey YOLO repository를 clone
        - cd ~/Desktop ; git clone https://github.com/AlexeyAB/darknet.git
        - cd ./darknet ; git checkout darknet_yolo_v3  
      - MakeFile을 열어 4라인의 OPENCV만 1로 변경
      - CUDA를 사용할 경우 GPU와 CUDNN 또한 1로 변경
      - 그리고 darknet프로젝트를 clone한 위치에서 명령 입력
        - $ make
  
    - Alexey YOLO 예제 실행 (Linux)
      - $ cd ~/Desktop/darknet
      - $ wget https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov3.cfg
      - $ wget https://pjreddie.com/media/files/yolov3.weights
      - $ ./darknet detector test ./cfg/coco.data ./yolov3.cfg ./yolov3.weights data/dog.jpg -i 0 -thresh 0.25

- YOLO 학습
  - 이미지 분류
    - YOLO 학습
      - YOLO를 학습시키려면 어떻게 해야 할까
        - 필요한 사진 데이터를 모으기
        - 사진 데이터에 라벨링
          - 각 사진에서 찾을 객체의 위치를 x, y, w, h로 만들어야 하는데, 이것이 매우 번거로운 일
          - Alexey가 라벨링 프로그램을 제작 배포했는데 그 프로그램이 YOLO Mark  
        - 학습시킬 버전을 선택
        - 학습
  
    - YOLO Mark 설치 - Linux
      - Alexey YOLO Mark repository clone
        - cd ~/Desktop && git clone https://github.com/AlexeyAB/Yolo_mark.git  
      - clone된 디렉토리로 들어가 다음 명령을 차례로 실행
        - $ cmake .
        - $ make
        - $ chmod +x ./linux_mark.sh
  
    - YOLO Mark 사용방법 - Linux
      - 우선 x64/Release/data/obj.names 파일을 열어 분류할 물체의 이름 적어주기
        - 만약 비행기와 새를 분류할 것이라면 첫번째 줄에 airplane, 두번째 줄에 bird라고 적고 저장하기
        - airplane은 0번 object, bird는 1번 object가 됨  
      - x64/Release/data/obj.data를 열어 classes= 부분 변경
        - 비행기와 새를 구분하는 모델을 만들고 있으므로 classes=2  
      - 마지막으로 라벨링할 이미지를 정리하여 yolo_mark 디렉토리 x64/Release/data/img에 넣기
      - linux_mark.sh를 실행
        - h를 누르면 단축키를 볼 수 있음
        - Image num: 라벨링할 이미지를 불러올 수 있는 스크롤, img 디렉토리에 넣은 이미지를 순차적으로 불러오며 중간에 썸내일을 클릭하는 방법으로도 해당 이미지로 이동 가능
        - Object ID: 지금 표시할 객체가 무엇인지 설정하는 스크롤
        - Linux_mark.sh을 실행 후 사진 위에 드래그 해보면 좌측처럼 드래그한 범위만큼 직사각형이 생성되며 거기에 0-airplane이라고 붙음
        - 그리고 object id 스크롤을 우측으로 당긴 후 0에서 1이 되는 것을 확인하고 다시 사진 위에 드래그 해보면 우측처럼 드래그한 범위만큼 직사각형이 생성되며 1-bird라고 붙음
        - 드래그하고 다음 사진으로 넘어가면, 프로그램 상단 썸내일에 녹색 체크 표시가 뜨는데 해당 체크는 라벨링 계싼을 완료했고 파일을 만들어 저장했다는 뜻
        - 실제로 해당 이미지 파일이 있는 경로로 가보면 txt 파일이 생성되어 있고, 해당 텍스트에 방금 라벨링한 데이터가 들어 있는 것을 확인할 수 있음
    - YOLO 학습 방법 - Linux
      - YOLO Mark를 통한 라벨링 작업이 끝났으면 학습 모델 고르기
      - 각 모델 특징
        - YOLOv2는 YOLOv3보다 속도가 빠름
        - Tiny는 일반보다 정확도가 낮으나, 속도가 훨씬 빠름
        - YOLOV4는 YOLOv3보다 정확도 상승
      - 우리는 ROS에서 Yolo를 사용할 것이기 때문에 감안해서 모델 고르기
        - 유서깊은 yolo ROS package인 darknet_ros가 있는데, 해당 패키지는 yolov3까지 지원함
        - 게다가 tx2로 yolov3를 구동시 fps가 2~3 정도가 나오므로(0.대 나오는 경우가 많음), 해당 부분을 감안하여 yolov2 또는 yolov2-tiny 선택하는 것이 좋음
        - Jetpack 3.2.1 버전이 설치된 B2에서는 최신의 Alexey YOLO 설치가 불가능(v4 사용이 불가능)
      - 모델을 선택했으면 그에 해당하는 사전 학습 파일 다운받기
        - YOLOv2 & YOLOv2-tiny: http://pjreddie.com/media/files/darknet19 448.conv.23
      - cfg 파일은 다음 URL에서 다운받기
        - https://raw.githubusercontent.com/AlexeyAB/darnket/darknet_yolo_v3/cfg/yolov2-tiny.cfg
      - 다운받은 cfg 파일을 열어 다음을 수정
        - 3번째 줄 batch=1 -> batch=64
        - 4번째 줄 subdivisions=1 -> subdivisions=8
        - 125번째 줄 classes=80 -> classes={분류할 class 수}
        - 119번째 줄 filters=425 -> filters={(분류할 class 수 + 5) * 5}
      - 다음 에러가 뜰 시 batch와 subdivisions 값 낮추기
        - darknet: ./src/utils.c331: void error(const char*): Assertion '0' failed
      - 수정이 완료되었으면 학습 시작하기
        - cd ~/selfdriving/darknet ; ./darknet detector train $HOME/selfdriving/Yolo_mark/x64/Release/data/obj.data cfg/yolov2-tiny.cfg darknet19_448.conv.23  
      - Tip
        - 학습을 시키기 위한 클래스당 이미지의 개수는 최소 2천개라 YOLO 매뉴얼에 적혀 있지만 실제로 테스트 해본 결과 300~400장 정도면 인식률이 아주 나쁘지 않은 것을 확인
        - 여기서 이미지의 개수는 모두 다른 자세, 다른 환경의 이미지를 의미
    - YOLO 학습 방법 - Windows
      - 첨부파일 darknet.zip 다운로드 후 압축 해제
      - 해당 버전은 Yolo CPU 버전
      - YOLO mark 사용법
        - darknet/yolo_mark.cmd 실행  
      - 학습 방법
        - YOLOv4: darknet/yolov4_train.cmd 실행
        - YOLOv3: darknet/yolov3_train.cmd 실행
        - YOLOv2: darknet/yolov2_train.cmd 실행  
      - 이미지 감지 예제
        - YOLOv4: darknet/yolov4_image_detect_example.bat
        - YOLOv3: darknet/yolov4_image_detect_example.bat
        - YOLOv2: darknet/yolov4_image_detect_example.bat
  
- YOLO의 실전 사용(darknet_ros 사용법)
  - darknet_ros 패키지
    - ros에서 가장 쉽게 YOLO를 사용할 수 있게 제작된 패키지
    - 현재 ROS 1에 대해서는 더 이상 업데이트가 되고 있지 않음
    - yolov3까지 구동 가능하며, tx2 보드 jetpack v3.x.x 에서 ROS와 동시에 사용할 때 애용되는 패키지 중 하나  
  
  - darknet_ros 패키지 설치
    - darknet_ros 설치
      - $ cd {ROS 사용자 workspace}/src
      - $ git clone https://github.com/leggedrobotics/darknet_ros.git
      - $ cd ./darknet_ros
      - $ git submodule init
      - $ git submodule update
      - $ cm  
    - catkin_make 시에 자동으로 yolov2, yolov2-tiny, yolov3 weight 파일을 다운로드
    - 만약 다운로드를 하고 싶지 않다면 darknet_ros/darknet_ros/CMakeList.txt 파일 수정
      - Line 231, 239, 253 주석 처리시, weight 파일을 다운받지 않음
  
  - darknet_ros 사용법
    - 구조
      - 카메라 노드
        - darknet_ros에게 카메라 이미지 전송  
      - darknet_ros
        - Main에게 박스가 표시된 이미지, 바운딩박스 위치 크기 정보, 감지된 개체 수 전송  
      - Main
  
    - 사용법
      - Google > ROS usb_cam > ros.org에서 다운받기
      - 받은 것을 /darknet_ros/darknet/ 위치에 저장
      - usb_cam/usb_cam/launch 
      - usb_cam/nodes/usb_cam_node.cpp 참고해서 확인해보기
      - darknet_ros/launch에서 darknet_ros.launch를 복사해주고 my_yolo.launch로 이름 변경
      - darknet_ros/config를 자세히 보기
        - ros.yaml: darknet yolo config 파일